{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T01:18:39.935086Z",
     "start_time": "2020-03-13T01:18:39.886689Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_HAS_OPS' from 'torchvision.extension' (/home/yuan/Xstudio/miniconda3/lib/python3.7/site-packages/torchvision/extension.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c6a693d5a72f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Xstudio/miniconda3/lib/python3.7/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_HAS_OPS' from 'torchvision.extension' (/home/yuan/Xstudio/miniconda3/lib/python3.7/site-packages/torchvision/extension.py)"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from dataloader import listflowfile as lt \n",
    "from dataloader import SecenFlowLoader as DA\n",
    "import utils.logger as logger\n",
    "from utils.utils import GERF_loss, smooth_L1_loss\n",
    "from models.StereoNet8Xmulti import StereoNet\n",
    "from os.path import join, split, isdir, isfile, splitext, split, abspath, dirname\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from easy_dict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T01:18:35.294112Z",
     "start_time": "2020-03-13T01:14:59.899327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Collecting torchvision==0.5.0\n",
      "\u001b[?25l  Downloading http://pypi.doubanio.com/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.0MB 59.6MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting torch==1.4.0 (from torchvision==0.5.0)\n",
      "\u001b[?25l  Downloading http://pypi.doubanio.com/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 753.4MB 4.7MB/s ta 0:00:0111/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: six in /home/yuan/Xstudio/miniconda3/lib/python3.7/site-packages (from torchvision==0.5.0) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/yuan/Xstudio/miniconda3/lib/python3.7/site-packages (from torchvision==0.5.0) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/yuan/Xstudio/miniconda3/lib/python3.7/site-packages (from torchvision==0.5.0) (1.18.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.3.0\n",
      "    Uninstalling torch-1.3.0:\n",
      "      Successfully uninstalled torch-1.3.0\n",
      "  Found existing installation: torchvision 0.4.1\n",
      "    Uninstalling torchvision-0.4.1:\n",
      "      Successfully uninstalled torchvision-0.4.1\n",
      "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T08:40:32.936390Z",
     "start_time": "2020-03-12T08:40:32.933717Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='StereoNet with Flyings3d')\n",
    "parser.add_argument('--maxdisp', type=int, default=192, help='maxium disparity')\n",
    "parser.add_argument('--loss_weights', type=float, nargs='+', default=[1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "parser.add_argument('--datapath', default='/media/lxy/sdd1/stereo_coderesource/dataset_nie/SceneFlowData', help='datapath')\n",
    "parser.add_argument('--epoch', type=int, default=15, help='number of epochs to train')\n",
    "parser.add_argument('--train_bsize', type=int, default=1,\n",
    "                    help='batch size for training(default: 1)')\n",
    "parser.add_argument('--itersize', default=1, type=int,\n",
    "                    metavar='IS', help='iter size')\n",
    "parser.add_argument('--test_bsize', type=int, default=1,\n",
    "                    help='batch size for test(default: 1)')\n",
    "parser.add_argument('--save_path', type=str, default='results/8Xmulti',\n",
    "                    help='the path of saving checkpoints and log')\n",
    "parser.add_argument('--resume', type=str, default=None, help='resume path')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight_decay', '--wd', default=2e-4, type=float,\n",
    "                    metavar='W', help='default weight decay')\n",
    "parser.add_argument('--stepsize', default=1, type=int, \n",
    "                    metavar='SS', help='learning rate step size')\n",
    "parser.add_argument('--gamma', '--gm', default=0.6, type=float,\n",
    "                    help='learning rate decay parameter: Gamma')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequence')\n",
    "parser.add_argument('--stages', type=int, default=4, help='the stage num of refinement')\n",
    "parser.add_argument('--gpu', default='0', type=str, help='GPU ID')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T08:40:32.936390Z",
     "start_time": "2020-03-12T08:40:32.933717Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    global args\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    train_left_img, train_right_img, train_left_disp, test_left_img, test_right_img, test_left_disp = lt.dataloader(\n",
    "        args.datapath)\n",
    "    train_left_img.sort()\n",
    "    train_right_img.sort()\n",
    "    train_left_disp.sort()\n",
    "\n",
    "    test_left_img.sort()\n",
    "    test_right_img.sort()\n",
    "    test_left_disp.sort()\n",
    "    \n",
    "\n",
    "    __normalize = {'mean': [0.0, 0.0, 0.0], 'std': [1.0, 1.0, 1.0]}\n",
    "    TrainImgLoader = torch.utils.data.DataLoader(\n",
    "        DA.myImageFloder(train_left_img, train_right_img, train_left_disp, True, normalize=__normalize),\n",
    "        batch_size=args.train_bsize, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "    TestImgLoader = torch.utils.data.DataLoader(\n",
    "        DA.myImageFloder(test_left_img, test_right_img, test_left_disp, False, normalize=__normalize),\n",
    "        batch_size=args.test_bsize, shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "    if not os.path.isdir(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "    log = logger.setup_logger(args.save_path + '/training.log')\n",
    "    for key, value in sorted(vars(args).items()):\n",
    "        log.info(str(key) + ':' + str(value))\n",
    "    \n",
    "    model = StereoNet(k=args.stages-1, r=args.stages-1, maxdisp=args.maxdisp)\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    model.apply(weights_init)\n",
    "    print('init with normal')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=args.stepsize, gamma=args.gamma)\n",
    "\n",
    "    log.info('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "    args.start_epoch = 0\n",
    "\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            log.info(\"=> loading checkpoint '{}'\".format((args.resume)))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            log.info(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            log.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "            log.info(\"=> will start from scratch.\")\n",
    "    else:\n",
    "        log.info(\"Not Resume\")\n",
    "    start_full_time = time.time()\n",
    "    for epoch in range(args.start_epoch, args.epoch):\n",
    "        log.info('This is {}-th epoch'.format(epoch))\n",
    "\n",
    "        train(TrainImgLoader, model, optimizer, log, epoch)\n",
    "\n",
    "        savefilename = args.save_path + '/checkpoint.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()},\n",
    "            savefilename)\n",
    "        scheduler.step() # will adjust learning rate\n",
    "    \n",
    "    test(TestImgLoader, model, log)\n",
    "    log.info('full training time = {: 2f} Hours'.format((time.time() - start_full_time) / 3600))\n",
    "\n",
    "\n",
    "\n",
    "def train(dataloader, model, optimizer, log, epoch=0):\n",
    "\n",
    "    stages = args.stages\n",
    "    losses = [AverageMeter() for _ in range(stages)]\n",
    "    length_loader = len(dataloader)\n",
    "    counter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (imgL, imgR, disp_L) in enumerate(dataloader):\n",
    "        \n",
    "        imgL = imgL.float().cuda()\n",
    "        imgR = imgR.float().cuda()\n",
    "        disp_L = disp_L.float().cuda()\n",
    "\n",
    "        outputs = model(imgL, imgR)\n",
    "        \n",
    "        \n",
    "\n",
    "        outputs = [torch.squeeze(output, 1) for output in outputs]\n",
    "        \n",
    "        loss = [GERF_loss(disp_L, outputs[0], args)]\n",
    "        for i in range(len(outputs)-1):\n",
    "            loss.append(GERF_loss(disp_L, outputs[i+1], args))\n",
    "\n",
    "        \n",
    "        counter +=1\n",
    "        loss_all = sum(loss)/(args.itersize)\n",
    "        loss_all.backward()\n",
    "        if counter == args.itersize:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            counter = 0\n",
    "\n",
    "        for idx in range(stages):\n",
    "            losses[idx].update(loss[idx].item()/args.loss_weights[idx])\n",
    "\n",
    "\n",
    "\n",
    "        if batch_idx % args.print_freq == 0:\n",
    "            info_str = ['Stage {} = {:.2f}({:.2f})'.format(x, losses[x].val, losses[x].avg) for x in range(stages)]\n",
    "            \n",
    "            info_str = '\\t'.join(info_str)\n",
    "\n",
    "            log.info('Epoch{} [{}/{}] {}'.format(\n",
    "                epoch, batch_idx, length_loader, info_str))\n",
    "\n",
    "            #vis\n",
    "            _, H, W = outputs[0].shape\n",
    "            all_results = torch.zeros((len(outputs)+1, 1, H, W))\n",
    "            for j in range(len(outputs)):\n",
    "                all_results[j, 0, :, :] = outputs[j][0, :, :]/255.0\n",
    "            all_results[-1, 0, :, :] = disp_L[:, :]/255.0\n",
    "            torchvision.utils.save_image(all_results, join(args.save_path, \"iter-%d.jpg\" % batch_idx))\n",
    "            # print(imgL)\n",
    "            im = np.array(imgL[0,:,:,:].permute(1,2,0)*255, dtype=np.uint8)\n",
    "        \n",
    "            cv.imwrite(join(args.save_path, \"itercolor-%d.jpg\" % batch_idx),im)\n",
    "\n",
    "    info_str = '\\t'.join(['Stage {} = {:.2f}'.format(x, losses[x].avg) for x in range(stages)])\n",
    "    log.info('Average train loss = ' + info_str)\n",
    "\n",
    "def test(dataloader, model, log):\n",
    "\n",
    "    stages = args.stages\n",
    "    # End-point-error\n",
    "    EPES = [AverageMeter() for _ in range(stages)]\n",
    "    length_loader = len(dataloader)\n",
    "\n",
    "    # model.eval()\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (imgL, imgR, disp_L) in enumerate(dataloader):\n",
    "        imgL = imgL.float().cuda()\n",
    "        imgR = imgR.float().cuda()\n",
    "        disp_L = disp_L.float().cuda()\n",
    "\n",
    "        mask = (disp_L < args.maxdisp) & (disp_L >= 0)\n",
    "        \n",
    "        # mask = disp_L < args.maxdisp\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(imgL, imgR)\n",
    "            for x in range(stages):\n",
    "            \n",
    "                if len(disp_L[mask]) == 0:\n",
    "                    EPES[x].update(0)\n",
    "                    continue\n",
    "                output = torch.squeeze(outputs[x], 1)\n",
    "                EPES[x].update((output[mask] - disp_L[mask]).abs().mean())\n",
    "                \n",
    "\n",
    "        info_str = '\\t'.join(['Stage {} = {:.2f}({:.2f})'.format(x, EPES[x].val, EPES[x].avg) for x in range(stages)])\n",
    "\n",
    "        log.info('[{}/{}] {}'.format(\n",
    "            batch_idx, length_loader, info_str))\n",
    "\n",
    "\n",
    "        #vis\n",
    "        # _, H, W = outputs[0].shape\n",
    "        # all_results = torch.zeros((len(outputs)+1, 1, H, W))\n",
    "        # for j in range(len(outputs)):\n",
    "        #     all_results[j, 0, :, :] = outputs[j][0, :, :]/255.0\n",
    "        # all_results[-1, 0, :, :] = disp_L[:, :]/255.0\n",
    "        # torchvision.utils.save_image(all_results, join(args.save_path, \"iter-%d.jpg\" % batch_idx))\n",
    "        # # print(imgL)\n",
    "        # im = np.array(imgL[0,:,:,:].permute(1,2,0)*255, dtype=np.uint8)\n",
    "        # print(im.shape)\n",
    "        # cv.imwrite(join(args.save_path, \"itercolor-%d.jpg\" % batch_idx),im)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # _, H, W = outputs[0].shape\n",
    "        # all_results_color = torch.zeros((H, 5*W))\n",
    "        # all_results_color[:,:W]= outputs[0][0, :, :]\n",
    "        # all_results_color[:,W:2*W]= outputs[1][0, :, :]\n",
    "        # # print(disp_L)\n",
    "        # all_results_color[:,2*W:3*W]= outputs[2][0, :, :]\n",
    "        # all_results_color[:,3*W:4*W]= outputs[3][0, :, :]\n",
    "        \n",
    "        # all_results_color[:,4*W:5*W]= disp_L[:, :]\n",
    "        \n",
    "\n",
    "        # im_color = cv.applyColorMap(np.array(all_results_color*2, dtype=np.uint8), cv.COLORMAP_JET)\n",
    "        # cv.imwrite(join(args.save_path, \"iterpredcolor-%d.jpg\" % batch_idx),im_color)\n",
    "\n",
    "    info_str = ', '.join(['Stage {}={:.2f}'.format(x, EPES[x].avg) for x in range(stages)])\n",
    "    log.info('Average test EPE = ' + info_str)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # xavier(m.weight.data)\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        if m.weight.data.shape == torch.Size([1, 5, 1, 1]):\n",
    "            # for new_score_weight\n",
    "            torch.nn.init.constant_(m.weight, 0.2)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        # xavier(m.weight.data)\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        if m.weight.data.shape == torch.Size([1, 5, 1, 1]):\n",
    "            # for new_score_weight\n",
    "            torch.nn.init.constant_(m.weight, 0.2)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Compute and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val= 0\n",
    "        self.avg= 0\n",
    "        self.sum= 0\n",
    "        self.count= 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
